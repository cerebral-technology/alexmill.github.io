---
layout: post
title: "Fourier Series, Python, $amp; Matplotlib &mdash; oh my!"
meta: "I decided to take a stab at recreating a popular Fourier series spinning circles visualization."
hero: /img/fourier-hero.png
categories: ["blog"]
author: "Alex Miller"
source: default
latex: true
syntax: false
date: 2018-03-08
---

The venerable [3Blue1Brown YouTube channel](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) came out with a [fantastic video on Fourier transforms](https://www.youtube.com/watch?v=spUNpyF58BY) 
a few weeks ago. Not long after, I came across this very cool gif of Vermeer's "Girl with
the Pearl Earring", which uses a clever visualization of Fourier approximations to "draw" 
the image with a series of animated, concatenated circles. 

<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Generative Art. <a href="https://t.co/5dW7uvDqHR">pic.twitter.com/5dW7uvDqHR</a></p>&mdash; じゃがりきん (@jagarikin) <a href="https://twitter.com/jagarikin/status/962449509782495232?ref_src=twsrc%5Etfw">February 10, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

I could not track the source of the image down, but&mdash;with the 3Blue1Brown video fresh in my mind&mdash;
I was thoroughly determined to understand the math behind this visualization. I took Fourier Analysis as a 
sophomore in college, but it has been quite a while since I really grokked the math behind it all. 

This led me on down the foolhardy path of recreating this visualization myself. It turns out, the math
behind it all isn't completley incomprehensible. The animation/visualization, on the other hand, is an
entirely different story (to be revisted shortly). As opposed to taking an engineer's approach to the 
problem (which may be more intuitive), I like to motivate Fourier analysis using linear algebra (which,
as would be expected from a math major, is more elegant). 

# A Crash Course in Fourier Analysis 
Starting with a simplistic example, note how vectors in 3-dimensional euclidean space can be represented as the sum of
three basis vectors: the point $(3,7,1)$ can be written as $3e_1 + 7e_2 + 1e_3$, where $e_k$ represent the
``canonical'' basis vectors of $\mathbb{R}^3$: 

$$e_1 = (1,0,0)$$
$$e_2 = (0,1,0)$$
$$e_3 = (0,0,1)$$

The key idea behind Fourier approximations is to think of functions themselves as objects in some infinite-dimensional
vector space. This seems weird at first, but if you've taken a college calculus course, you may already have some intuition
for how this might work. The key to understanding vectors in a vector space is to identify a basis of that space (this is 
essentially what linear algebra is all about). What would a basis for the infinite-dimensional vector space of functions look
like? If you've ever seen Taylor series expansions, then you've essentially already solved this problem. 

Note how the Taylor series of a function allows us to represent any function as an infinite sum of some set of coefficients
$a_n$ times the monomials $x^n$

$$f(t) = \sum_{n=1}^\infty a_n x^n$$

In terms of linear algebra, this means that the set of monomial powers $\{ x^n : n \in \mathbb{N} \}$ forms a basis over the
infinite-dimensional space of continuous single-variable functions. 

If you've taken linear algebra, you may also be familiar with the notion of orthogonality. I won't get too far into 
the weeds of defining abstract inner-product spaces, but essentially

This brings us to the main idea behind Fourier series: the functions $\sin(nt)$ and $\cos(nt)$ form an orthogonal basis 
over the vector space of functions with respect to the metric of integration over the real line.

The beauty of thinking about Fourier series in these terms 


